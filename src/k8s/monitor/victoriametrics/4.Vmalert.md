---
author: Ryan
title: 4.Vmalert
date: 2024-02-29
tags: [VictoriaMetrics]
sidebar_position: 4
---


## 简介


前面我们已经介绍了可以使用 vmagent 代替 prometheus 抓取监控指标数据，要想完全替换 prometheus 还有一个非常重要的部分就是报警模块，之前我们都是在 prometheus 中定义报警规则评估后发送给 alertmanager 的，同样对应到 vm 中也有一个专门来处理报警的模块：**vmalert**。<br />vmalert 会针对 `**-datasource.url**` 地址执行配置的报警或记录规则，然后可以将报警发送给 `**-notifier.url**` 配置的 Alertmanager，记录规则结果会通过远程写入的协议进行保存，所以需要配置 **-remoteWrite.url**。


## 特性

- 与 VictoriaMetrics TSDB 集成
- VictoriaMetrics MetricsQL 支持和表达式验证
- Prometheus 告警规则定义格式支持
- 与 Alertmanager 集成
- 在重启时可以保持报警状态
- Graphite 数据源可用于警报和记录规则
- 支持记录和报警规则重放
- 非常轻量级，没有额外的依赖

**要开始使用 vmalert，需要满足以下条件：**

- 报警规则列表：要执行的 PromQL/MetricsQL 表达式
- 数据源地址：可访问的 VictoriaMetrics 实例，用于规则执行
- 通知程序地址：可访问的 Alertmanager 实例，用于处理，汇总警报和发送通知

## 部署**Vmalert**
### 安装 Alertmanager
首先需要安装一个 Alertmanager 用来接收报警信息，前面章节中我们已经详细讲解过了，这里不再赘述了，对应的资源清单如下所示：
```yaml
# vm-alertmanager.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alert-config
  namespace: vm-cluster
data:
  config.yml: |-
    global:
      resolve_timeout: 5m
      smtp_smarthost: 'smtp.163.com:465'
      smtp_from: 'xc522cv@163.com'
      smtp_auth_username: 'xc522cv@163.com'
      smtp_auth_password: 'KMXQWCCIRXBDAITA'  # 使用网易邮箱的授权码
      smtp_hello: '163.com'
      smtp_require_tls: false
    route:
      group_by: ['severity', 'source']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 24h
      receiver: email
    receivers:
    - name: 'email'
      email_configs:
      - to: '562188771@qq.com'
        send_resolved: true
---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: vm-cluster
  labels:
    app: alertmanager
spec:
  selector:
    app: alertmanager
  type: NodePort
  ports:
    - name: web
      port: 9093
      nodePort: 30094
      targetPort: http
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: vm-cluster
  labels:
    app: alertmanager
spec:
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      volumes:
        - name: cfg
          configMap:
            name: alert-config
      containers:
        - name: alertmanager
          image: prom/alertmanager:v0.24.0
          imagePullPolicy: IfNotPresent
          args:
            - "--config.file=/etc/alertmanager/config.yml"
          ports:
            - containerPort: 9093
              name: http
          volumeMounts:
            - mountPath: "/etc/alertmanager"
              name: cfg

```

Alertmanager 这里我们只配置了一个默认的路由规则，根据 severity、source 两个标签进行分组，然后将触发的报警发送到 email 接收器中去。

### 配置 Vmalert 报警规则

接下来需要添加用于报警的规则配置，配置方式和 Prometheus 一样的：
```yaml
# vmalert-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: vmalert-config
  namespace: vm-cluster
data:
  record.yaml: |
    groups:
    - name: record
      rules:
      - record: job:node_memory_MemFree_bytes:percent  # 记录规则名称
        expr: 100 - (100 * node_memory_MemFree_bytes / node_memory_MemTotal_bytes)
  pod.yaml: |
    groups:
    - name: pod
      rules:
      - alert: PodMemoryUsage
        expr: sum(container_memory_working_set_bytes{pod!=""}) BY (instance, pod)  / sum(container_spec_memory_limit_bytes{pod!=""} > 0) BY (instance, pod) * 100 > 60
        for: 2m
        labels:
          severity: warning
          source: pod
        annotations:
          summary: "Pod {{ $labels.pod }} High Memory usage detected"
          description: "{{$labels.instance}}: Pod {{ $labels.pod }} Memory usage is above 60% (current value is: {{ $value }})"
  node.yaml: |
    groups:
    - name: node
      rules:  # 具体的报警规则
      - alert: NodeMemoryUsage  # 报警规则的名称
        expr: (node_memory_MemTotal_bytes - (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes)) / node_memory_MemTotal_bytes * 100 > 30
        for: 1m
        labels:
          source: node
          severity: critical
        annotations:
          summary: "Node {{$labels.instance}} High Memory usage detected"
          description: "{{$labels.instance}}: Memory usage is above 30% (current value is: {{ $value }})"
```


这里我们添加了一条记录规则，两条报警规则，更多报警规则配置可参考 [https://awesome-prometheus-alerts.grep.to/](https://awesome-prometheus-alerts.grep.to/)。

### 部署 Vmalert
上面的资源清单中将报警规则以 volumes 的形式挂载到了容器中，通过 `-rule` 指定了规则文件路径，`-datasource.url` 指定了 vmselect 的路径，`-notifier.url` 指定了 Alertmanager 的地址，其中` -evaluationInterval` 参数用来指定评估的频率的，由于我们这里添加了记录规则，所以还需要通过 `-remoteWrite.url` 指定一个远程写入的地址。

```yaml
# vmalert.yaml
apiVersion: v1
kind: Service
metadata:
  name: vmalert
  namespace: vm-cluster
  labels:
    app: vmalert
spec:
  ports:
    - name: vmalert
      port: 8080
      targetPort: 8080
      nodePort: 30093
  type: NodePort
  selector:
    app: vmalert
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vmalert
  namespace: vm-cluster
  labels:
    app: vmalert
spec:
  selector:
    matchLabels:
      app: vmalert
  template:
    metadata:
      labels:
        app: vmalert
    spec:
      containers:
        - name: vmalert
          image: victoriametrics/vmalert:v1.77.0
          imagePullPolicy: IfNotPresent
          args:
            - -rule=/etc/ruler/*.yaml
            - -datasource.url=http://vmselect.vm-cluster.svc.cluster.local:8481/select/0/prometheus
            - -notifier.url=http://alertmanager.vm-cluster.svc.cluster.local:9093
            - -remoteWrite.url=http://vminsert.vm-cluster.svc.cluster.local:8480/insert/0/prometheus
            - -evaluationInterval=15s
            - -httpListenAddr=0.0.0.0:8080
          volumeMounts:
            - mountPath: /etc/ruler/
              name: ruler
              readOnly: true
      volumes:
        - configMap:
            name: vmalert-config
          name: ruler
```


### 查看各服务运行状态
```bash
$ kubectl apply -f vmalert-config.yaml
configmap/vmalert-config created

$ kubectl apply -f vm-alertmanager.yaml
configmap/alert-config created
service/alertmanager created
deployment.apps/alertmanager created

$ kubectl apply -f vmalert.yaml
service/vmalert created
deployment.apps/vmalert created



$ kubectl get pod -n vm-cluster
NAME                           READY   STATUS    RESTARTS   AGE
alertmanager-dd8fb4858-mkkwx   1/1     Running   0          3m16s
vmagent-0                      1/1     Running   0          39m
vmagent-1                      1/1     Running   0          38m
vmalert-69644ddc4c-tt7tn       1/1     Running   0          74s
vminsert-6687ddd759-tpmj5      1/1     Running   0          23h
vmselect-864dbbfc6d-mhkct      1/1     Running   0          23h
vmstorage-0                    1/1     Running   0          41h
vmstorage-1                    1/1     Running   0          2d1h

----------------------------------------------------------------------------------------------
$ kubectl get svc -n vm-cluster
NAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
alertmanager        NodePort    10.96.101.49    <none>        9093:30094/TCP               4m45s
cluster-vmstorage   ClusterIP   None            <none>        8482/TCP,8401/TCP,8400/TCP   2d1h
vmagent-svc         NodePort    10.100.189.5    <none>        8429:30429/TCP               41m
vmalert             NodePort    10.97.36.203    <none>        8080:30093/TCP               2m43s
vminsert            ClusterIP   10.98.43.246    <none>        8480/TCP                     2d1h
vmselect            NodePort    10.102.61.237   <none>        8481:30092/TCP               2d1h
```


部署成功后，如果有报警规则达到了阈值就会触发报警，我们可以通过 Alertmanager 页面查看触发的报警规则：


![c2411c65b2f7](http://img.xinn.cc/c2411c65b2f7.png)

![80ea1dbd24d4](http://img.xinn.cc/80ea1dbd24d4.png)




同样 vmalert 也提供了一个简单的页面，可以查看所有的 Groups：<br />

![08b9a1856936](http://img.xinn.cc/08b9a1856936.png)




也可以查看到报警规则列表的状态：<br />


![2e7d6855e926](http://img.xinn.cc/2e7d6855e926.png)


![eafe28b7dba5](http://img.xinn.cc/eafe28b7dba5.png)



还可以查看到具体的一条报警规则的详细信息，如下所示：<br />
![c6e765c9b5e2433](http://img.xinn.cc/c6e765c9b5e2433.png)


报警规则触发后怎么发送，发送到哪个接收器就是 Alertmanager 决定的了。<br />同样的上面我们添加的记录规则会通过 remote write 传递给 vminsert 保留下来，所以我们也可以通过 vmselect 查询到。<br />


![d7fe0a5c3bcc](http://img.xinn.cc/d7fe0a5c3bcc.png)


<br />到这里基本上我们就完成了使用 vm 代替 prometheus 来进行监控报警了，vmagent 采集监控指标，vmalert 用于报警监控，vmstorage 存储指标数据，vminsert 接收指标数据，vmselect 查询指标数据，已经完全可以不使用 prometheus 了，而且性能非常高，所需资源也比 prometheus 低很多。



---

## VictoriaMetrics 集群UI界面
VMUI：[http://192.168.18.7:30092/select/0/vmui](http://192.168.18.7:30092/select/0/vmui)<br />Alertmanager UI ：[http://192.168.18.8:30094/](http://192.168.18.8:30094/)<br />Vmalert UI: [http://192.168.18.8:30093/](http://192.168.18.8:30094/)<br />Grafana：[http://192.168.18.7:31799/](http://192.168.18.7:31799/)<br />Vmagent： [http://192.168.18.7:30429/targets](http://192.168.18.7:30429/targets)
