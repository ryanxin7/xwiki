---
author: Ryan
title: Ceph 集群维护 （四）
date: 2023-01-12
lastmod: 2023-05-31
tags: 
    - 分布式存储
categories: 
   - Ceph
expirationReminder:
  enable: true
---

ceph集群配置、部署与运维

[http://docs.ceph.org.cn/rados/](http://docs.ceph.org.cn/rados/) 

## 4.1:通过套接字进行单机管理
每个node节点上都有不同数量的OSD数量

启动osd进程会在 /var/run/ceph下生成soke文件
```bash
ls /var/run/ceph
ceph-osd.0.asok=
ceph-osd.1.asok=
ceph-osd.2.asok=
ceph-osd.3.asok=
ceph-osd.4.asok=
```

### 可在node节点或者mon节点通过ceph命令进行单机管理本机的mon或者osd服务
先将admin认证文件同步到mon或者node节点

```bash
ceph@ceph-deploy:/home/ceph/ceph-cluster$scp ceph.client.admin.keyring root@172.31.6.101:/etc/ceph

#指定要管理的asok文件
[root@ceph-node1 ~]# ceph -- admin-socket /var/run/ceph/ceph-osd.0.asok --help

```

![image.png](https://cdn1.ryanxin.live/xxlog/1669618980856-1b869d03-8ae2-4b8b-9b2a-4125d7a4bb01.png)


`-- admin-daemon`  在 mon节点获取daemon服务帮助:
```bash
#帮助信息: 
ceph-mon1~]#ceph --admin-daemon /var/run/ceph/ceph-mon.cephjmon1.asok help

#mon状态:
ceph-mon1~]# ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-mon1.asok mon_ status

#查看配置信息:
ceph-mon1~]# ceph - admin-daemon /var/run/ceph/ceph-mon.ceph-mon1.asok config show
```


## 4.2 ceph集群的停止或重启
重启之前按照正确的流程，要提前设置ceph集群不要将OSD标记为out,避免node节点关闭服务后被踢出ceph集群外

node节点每隔6s向mon节点汇报一次OSD状态，连续20秒后没有通告正常mon就会把OSD标记为OUT ，就会触发磁盘的高可用开始磁盘的选举和数据同步。
```bash
#关闭服务前设置noout
[ceph@ceph-deploy ceph-cluster]$ ceph osd set noout 
noout is set

#启动服务后取消noout
[ceph@ceph-deploy ceph-cluster]$ ceph osd unset noout 
noout is unset
```

### 4.2.1 关闭顺序

1. 关闭服务前设置noout
2. 关闭存储客户端停止读写数据
3. 如果使用RGW，关闭RGW
4. 关闭cephfs 元数据服务
5. 关闭ceph OSD
6. 关闭ceph manager
7. 关闭 ceph monitor
### 4.2.2 启动顺序

1. 启动 ceph monitor
2. 启动 ceph manager
3. 启动 ceph OSD
4. 启动 ceph FS 元数据服务
5. 启动RGW
6. 启动存储客户端
7. 启动服务后取消 noout 


### 4.2.3 服务时间偏差
[http://docs.ceph.org.cn/rados/configuration/mon-config-ref/](http://docs.ceph.org.cn/rados/configuration/mon-config-ref/)

重启发现：
> cluster:
>    id:5ac860ab- 9a4e- 4edd- 9da2 e3de293a8d44
>    health: HEALTH WARN
>                clock skew detected on mon. ceph-mon2, mon. ceph-mon3
>                noout flag(s) set



通常由于服务器重启后导致时间不太一致，因为服务器有时间同步计划任务同步周期还没到

可以设置监视器运行的时钟漂移量，默认为0.050秒即50毫秒
```bash
cat /ceph.conf
#设置监视器运行的时钟漂移量
mon clock drift allowed =3

#时钟偏移警告的退避指數即连续多少次时间偏差后就出发警告
mon clock drift warn backoff= 10


#同步配置文件mon服务器
[ceph@ceph-deploy ceph-cluster]$ ceph-deploy --overwrite-conf config push stor01..3)

#重启mon
#拷贝方式
#ceph@ceph-deploy:~/ceph-cluster$ scp ceph.conf root@172.31.6.101: /etc/ceph/
#ceph@ceph-deploy:~/ceph-cluster$ scp ceph.conf root@172.31.6.102: /etc/ceph/
#ceph@ceph-deploy:~/ceph-cluster$ scp ceph.conf root@172.31.6.103: /etc/ceph/


[root@ceph-mon1 ~]# ntpdate timel.aliyun.com && hwclock -W
root@ceph-mon1:~# systemctl restart ceph-mon@ceph-mon1.service

```


## 4.3 ceph 配置文件

Ceph的主配置文件是`/etc/ceph/ceph.conf `，ceph 服务在启动时会检查ceph.conf分号;和#在配置文件中都是注释，**ceph.conf** 主要由以下配置段组成:

:::info
**[global] **#全局配置**[osd]** #osd专用配置，可以使用osd.N, 来表示某一个OSD专用配置，N为osd的编号，如0、2、1等，

**[mon]** #mon专用配置，也可以使用mon.A来为某一个monitor节点做专用配置，其中A为该节点的名称，ceph-monitor-2、 ceph-monitor-1 等，使用命令ceph mon dump可以获取节点的名称、

**[client]** #客户端专用配置.
:::

**ceph 文件的加載順序**
```bash
$CEPH_CONF 环境变量
-c 指定配置文件位置
/etc/ceph/ceph.conf
~/.ceph/ceph.conf
./ceph.conf
```

## 4.4 存储池、PG与CRUSH
:::info
**副本池:repicated**,定义每个对象在集群中保存为多少个副本，默认为三个副本, 一主两备,实现高可用，副本池是ceph默认的存储池类型.
:::

在创建存储池的时候可以指定默认是三副本`osd pool create pool --help [replicated]` 

:::info
**纠删码池(erasure code)**: ceph另一种数据可用性机制一定程度上实现数据高可用（使用的不多），存储机制类似于raid5 把一部分存储空间用于存放校验码实现数据恢复的目的，既可以提高磁盘空间利用率，又能实现一定程度上的数据高可用。和raid机制一样不能坏一定数量的磁盘所以高可用机制有限。
:::



但是不是所有应用都支持纠删码池，RDB块存储只支持副本池而radosgw 可以支持纠删码池

**一部分存数据、一部分存校验码**



![image.png](https://cdn1.ryanxin.live/xxlog/1669691960330-9d8aa14f-ec4b-4d76-a6df-2a40bfc26a09.png)

把各对象存储为**N=K+M个块**，其中K为数据块数量，M为编码快数量，因此存储池的尺寸为K+M.



即数据保存在K个数据块,并提供M个冗余块提供数据高可用，那么最多能故障的块就是M个,实际的磁盘占用就是K+M块，因此相比副本池机制比较节省存储资源。

一般采用8+4机制，即8个数据块+4个冗余块，那么也就是12个数据块有8个数据块保存数据,有4个实现数据冗余，即1/3的磁盘空间用于数据冗余，比默认副本池的三倍冗余节省空间,但是不能出现大于一定数据块故障。



**但是不是所有的应用都支持纠删码池，RBD只支持副本池而Tjadosgw则可以支持纠删码池。**


创建**纠删码池**
```bash
ceph osd pool create erasure-testpool 32 32 erasure
```

写入数据
```bash
sudo rados put -p erasure-testpool testfile1 /var/log/syslog
```

验证数据
```bash
ceph osd map erasure-testpool testfile1
```

验证当前pg状态
```bash
ceph pg ls-by-pool erasure-testpool | awk '{print $1,$2,$15}'
```
### 4.4.1 副本池

**将一个数据对象存储为多个副本**

在客户端写入操作时，ceph使用CRUSH算法计算出与对象相对应的**PG ID**和**primary OSD**

主OSD根据设置的副本数、对象名称、存储池名称和**集群运行图(cluster map)**计算出PG

的各辅助OSD，然后由OSD将数据再同步给辅助OSD.

**读取数据:**

1.客户端发送读请求，**RADOS** 将请求发送到主OSD.

2.主OSD从本地磁盘读取数据并返回数据，最终完成读请求。

**写入数据:**



1. 客户端**APP**请求写入数据，**RADOS**发送数据到主OSD.
2. 主OSD识别副本OSDs,并发送数据到各副本OSD.
3. 副本OSDs写入数据，并发送写入完成信号给主OSD.
4. 主OSD发送写人完成信号给客户端APP.

![image.png](https://cdn1.ryanxin.live/xxlog/1669702054632-6c88be77-c67d-42d9-8253-ff988889159c.png)![image.png](https://cdn1.ryanxin.live/xxlog/1669702079911-981a98c9-e7cd-42b2-80c5-f224c76ed860.png)

### 4.4.2 纠删码池
纠删码池降低了数据保存所需要的磁盘总空间数量，但是读写数据的计算成本要比副本池高RGW可以支持纠删码池，RBD 不支持纠删码池可以降低企业的前期TCO总拥有成本。


**纠删码写:**数据将在主OSD进行编码然后分发到相应的OSDs.上去。1.计算合适的数据块并进行编码2.对每个数据块进行编码并写入OSD

**纠删码读:**从相应的OSDs中获取数据后进行解码，如果此时有数据丢失，Ceph 会自动从存放校验码的OSD中读取数据进行解码。


![image.png](https://cdn1.ryanxin.live/xxlog/1669702129781-75cd2740-58be-4f4b-9f7d-22b25657463e.png)

## 4.5 PG与PGP
:::info
**PG = Placement Group** 归置组**PGP = Placement Group for Placement purpose** 归置组的组合， pgp 相当于是pg对应osd的一种排列组合关系。
:::

**归置组(placement group)**是用于跨越多OSD将数据存储在每个存储池中的内部数据结构.归置组在OSD守护进程和ceph客户端之间生成了一个中间层，**CRUSH** 算法负责将每个对象动态映射到一个归置组，然后再将每个归置组动态映射到一个或多个OSD守护进程,从而能够支持在新的OSD设备上线时进行数据重新平衡。

相对于存储池来说，PG是一个虚拟组件，它是对象映射到存储池时使用的虚拟层。根据业务的数据量分配PG 一般 几百个G16和32就可以，TB级 64 到128。2的次方  ![image.png](https://cdn1.ryanxin.live/xxlog/1669715338535-50c64e93-251b-4de6-bf56-0e529abb82e6.png)

想对于存储池来说，PG 是一个虚拟组件，它是对象映射到存储池时使用的虚拟层。可以自定义存储池中的归置组数量。

ceph出于规模伸缩及性能方面的考虑，ceph 将存储池细分为多个归置组，把每个单独的对象映射到归置组，并为归置组分配一个主OSD.

存储池由一系列的归置组组成，而CRUSH算法则根据集群运行图和集群状态，将个PG均匀、伪随机(基于hash映射，每次的计算结果够 样)的分布到集群中的OSD之上。如果某个OSD失败或需要对集群进行重新平衡，ceph 则移动或复制整个归置组而不需要单独对每个镜像进行寻址。

## 4.6 PG与 OSD的关系
ceph基于crush算法将归置组PG分配至OSD当一个客户端存储对象的时候，CRUSH 算法映射每一个对象至归置组(PG) ![image.png](https://cdn1.ryanxin.live/xxlog/1669722018056-814dc21a-3afa-47a6-b007-9ca1238be466.png)


##  4.7 PG分配计算
**归置组(PG)**的数量是由管理员在创建存储池的时候指定的，然后由**CRUSH**负责创建和使用，PG的数量是2的N次方的倍数,每个OSD的PG不要超出250个PG，官方是每个OSD100个左右

一个磁盘可能属于多个PG分别担任不同的角色，[https://docs.ceph.com/en/mimic/rados/configuration/pool-pg-config-ref/](https://docs.ceph.com/en/mimic/rados/configuration/pool-pg-config-ref/)


**recommend approximately**确保设置了合适的归置组大小，我们建议每个OSD大约100个，例如，osd 总数乘以100除以副本数量(即 osd池默认大小)，因此，对于10个osd、**存储池为4个，我们建议每****个存储池大约(100 * 10) /4= 250**

**先算磁盘数量是多少块，官方推荐每个OSD是100个PG左右，10块就是1000个PG**

**PG的数量在集群分发数据和重新平衡时扮演者重要的角色**

PG的数量过少，PG的数量在ceph同步数据时有短暂影响，一个OSD上保存的数据数据会相对加多，那么ceph同步数据的时候产生的网络负载将对集群的性能输出产生一定影响。  **PG数量太少 数据量又大，那么必然同步是时间就长** PG过多的时候，ceph将会占用过多的CPU和内存资源用于记录PG的状态信息

至于一个pool应该使用多少个PG，可以通过下面的公式计算后，将pool的PG值四舍五人到最近的2的N次幂，如下先计算出ceph集群的总PG数:

**磁盘总数x每个磁盘PG数/副本数=> ceph集群总PG数(略大于2^n次方)****单个pool的PG计算如下:**
:::info
有100个osd,3副本，5个poolTotal PGS =100*100/3-3333每个pool的PG=3333/5=512.那么创建pool的时候就指定pg为512
:::
需要结合数据数量、磁盘数量及磁盘空间计算出PG数量，8、16、 32、64、128、 256等2的N次方。一个RADOS集群上会存在多个存储池，因此管理员还需要考虑所有存储池上的PG分布后每个OSD需要映射的PG数量.



## 4.8 PG的状态
### 4.8.1:Peering
正在同步状态，同一个PG中的OSD需要将准备数据同步一致, 而Peering(对等)就是OSD同步过程中的状态。
### 4.8.2:Activating
Peering已经完成，PG 正在等待所有PG实例同步Peering的结果(info、Log等)

### 4.8.3 Clean
磁盘没有宕机  干净态,PG当前不存在待修复的对象，并且大小等于存储池的副本数，即PG的活动集(Acting Set)和上行集(Up Set)为同一组OSD且内容一致。

活动集(Acting Set):由PG当前主的OSD和其余处于活动状态的备用OSD组成，当前PG内的OSD负责处理用户的读写请求。

上行集(Up Set):在某一个OSD故障时，需要将故障的OSD更换为可用的OSD,并主PG内部的主OSD同步数据到新的OSD上，例如PG内有OSD1、OSD2、OSD3，当OSD3故障后需要用OSD4替换OSD3,那么OSD1. OSD2、OSD3就是上行集，替换后OSD1、OSD2、OSD4就是活动集，OSD 替换完成后活动集最终要替换上行集。

###  4.8.4 Active
正常就绪状态或活跃状态，Active 表示主OSD和备OSD处于正常工作状态，此时的PG可以正常处理来自客户端的读写请求，正常的PG默认就是Active+Clean状态。


### 4.8.5 Degraded 降级状态
一般出现在磁盘宕机后，并且一段时间没有恢复降级状态出现于OSD被标记为down以后，那么其他映射到此OSD的PG都会转换到降级状态。如果此OSD还能重新启动完成并完成Peering操作后,那么使用此OSD的PG将重新恢复为clean状态。如果此OSD被标记为down的时间超过5分钟还没有修复，那么此OSD将会被ceph踢出集群，然后ceph会对被降级的PG启动恢复操作，直到所有由于此OSD而被降级的PG重新恢复为clean状态。恢复数据会从PG内的主OSD恢复，如果是主OSD故障，那么会在剩下的两个备用OSD重新选择一个作为主OSD.



### 4.8.6 Stale:过期状态
发生在OSD主宕了，数据不是最新正常状态下，每个主OSD都要周期性的向RADOS集群中的监视器(Mon)报告其作为主OSD所持有的所有PG的最新统计数据，因任何原因导致某个OSD无法正常向监视器发送汇报信息的、或者由其他OSD报告某个OSD已经down的时候，则所有以此OSD为主PG则会立即被标记为stale 状态，即他们的主OSD已经不是最新的数据了，如果是备份的OSD发送down的时候，则ceph会执行修复而不会触发PG状态转换为stale状态不会切换主。


### 4.8.7 undersized 
一主两副本，备宕了 出现副本数太低了PG当前副本数小于其存储池定义的值的时候，PG会转换为**undersixed**状态，比如两个备份OSD都down了，那么此时PG中就只有一个主OSD了，不符合ceph最少要求一个主OSD加一个备OSD的要求，那么就会导致使用此OSD的PG转换为undersized状态，直到添加备份OSD添加完成，或者修复完成。


### 4.8.8 Scrubbing 
每天进行数据的浅清理（整理元数据），每周进行数据的深清理（整理元数据和数据本身）scrub是ceph对数据的清洗状态，用来保证数据完整性的机制, Ceph的OSD定期启动scrub线程来扫描部分对象，通过与其他副本比对来发现是否一致， 如果存在不一致,抛出异常提示用户手动解决。scrub 以PG为单位，对于每一个pg, ceph 分析该pg下所有的object,产生一个类似于元数据信息摘要的数据结构,如对象大小，属性等,叫scrubmap,比较主与副scrubmap,来保证是不是有object丢失或者不匹配，扫描分为轻量级扫描和深度扫描，轻量级扫描也叫做**light scrubs**或者**shallow scrubs**或者simply scrubs即轻量级扫描.Light scrub(daily)比较object size和属性，deep scrub (weekly)读取数据部分并通过checksum(CRC32算法)对比和数据的一致性,深度扫描过程中的PG会处scrubbing +deep状态.


### 4.8.9:Recovering:
正在恢复态，集群正在执行迁移或同步对象和他们的副本，这可能是由于添加了一个新的OSD到集群中或者某个OSD宕掉后，PG可能会被CRUSH算法重新分配不同的OSD,而由于OSD更换导致PG发生内部数据同步的过程中的PG会被标记为Recovering.


### 4.8.10 Backfilling
正在后台填充态,backfill是recovery的一种特殊场景, 指peering完成后，如果基于当前权威日志无法对Up Set (. 上行集)当中的某些PG实例实施增量同步(例如承载这些PG实例的OSD离线太久,或者是新的OSD加入集群导致的PG实例整体迁移)则通过完全拷贝当前Primary所有对象的方式进行**全量同步**，此过程中的PG会处于backilling.

### 4.8.11 Backfill-toofull 
某个需要被Backfill的PG实例，其所在的OSD可用空间不足，Backfill 流程当前被挂起时PG给的状态。



## 4.9 ceph存储池操作
存储池的管理通常保存创建、列出、重命名和删除等操作，管理工具使用ceph osd pool的子命令及参数，比如create/ls/rename/rm等。ceph官方运维手册[http://docs.ceph.org.cn/rados/](http://docs.ceph.org.cn/rados/) 


### 4.9.1 常用命令 
**创建存储池命令格式**
```bash
$ceph osd pool create <poolname> pg. num pgp_ num {replicatedlerasure}

#列出存储池:
[ceph@ceph-deploy ceph-cluster]$ ceph osd poolls [detail] #不带 pool ID
mypool
myrdb1
.rgw.root
default.rgw.control 
default.rgw.meta
default.rgw.log
cephfs-metadata
cephfs-data

#带pool ID
ceph osd poolls

#查看详细
ceph osd pool ls detail

#查看存储池的事件信息
ceph osd pool stats mypool

#重命名存储池
ceph osd pool rename old-name new-name
ceph osd pool rename myrbd1 myrbd2

#显示存储池用量
ceph df
rados df 
```

### 4.9.2 删除存储池
ceph为了防止误删除存储池设置了两个机制来防止误删除操作。

**第一个机制**是NODELETE 标志,需要设置为false 但是默认就是FALSE。

```bash
#创建一个测试pool
ceph osd pool create mypool2 32 32

ceph osd pool get mypool2 nodelete
nodelete：false
#如果设置了为true就表示不能删除，可以使用set指令重新设置为false

ceph osd pool set mypool2 nodelete true
set pool 9 nodelete to true

```
**第二个机制**是集群范围的配置参数**mon allow pool delete**,默认值为false,即监视器不允许删除存储池，可以在特定场合使用tell指令临时设置为(true)允许删除,在删除指定的pool之后再重新设置为false.

```bash
$ ceph tell mon.* injectargs --mon-allow-pool-delete=true
mon.ceph-mon1:injectargs:mon_allow_pool delete = 'true'
mon.ceph-mon2:injectargs:mon_allow_pool delete = 'true'
mon.ceph-mon3:injectargs:mon_allow_pool delete = 'true'
$ ceph osd pool rm mypool2 mypool2 --yes-i-really-really-mean-it
pool 'mypool2' removed
```

### 4.9.3 存储池配额
存储池可以设置两个配对存储的对象进行限制，一个配额是**最大空间(max_ bytes**), 另外一个配额是对象**最大数量(max_ objects)**。

```bash
#查看存储池限制
$ ceph osd pool get-quota mypool 
quotas for pool 'mypool':
   max objects: N/A #默认不限制对象数量
   max bytes : N/A #默认不限制空间大小

----

$ ceph osd pool set-quota mypool max_objects 1000 #限制最大1000个对象
set-quota max_objects = 1000 for pool mypool


[ceph@ceph-deploy ceph-cluster]$ ceph osd pool set-quota mypool max_bytes 10737418240 #限制最大10737418240字节
set-quota max_bytes = 10737418240 for pool mypool

```
### 4.9.4 存储池可用参数

`size`: 存储池中的对象副本数，默认一主两个备3副本

`min_size`: **提供服务所需要的最小副本数**，如果定义size为3, min_size 也为3,坏掉一个OSD,如果pool池中有副本在此块OSD上面，那么此pool将不提供服务，如果将min_size定义为2，那么还可以提供服务，如果提供为1.表示只要有一块副本都提供服务。

`pg_num:` 查看当前PG的数量`crush_rule:` 设置crush算法规则`crush_ rule`:  默认为副本池`nodelete`:控制是否可删除，默认可以`nopgchange`: 控制是否可更改存储池的pg num和pgp num`nosizechange`: 控制是否可以更改存储池的大小`noscrub`和`nodeep-scrub`:控制是否不进行轻量扫描或是否深层扫描存储池，可临时解决高l/0问题`scrub_min_interval`: 集群存储池的最小清理时间间隔，默认值没有设置，可以通过配置文件中的`osd_scrub_min_interval` 参数指定间隔时间.

`scrub_max_interval`: 整理存储池的最大清理时间间隔，默认值没有设置，可以通过配置文件中的`osd_scrub_max_interval` 参数指定。

`deep_scrub_interval`: 深层整理存储池的时间间隔，默认值没有设置，可以通过配置文件中的`osd_deep_scrub_interval` 参数指定。

```bash
#查看副本数
ceph osd pool get mypool size
size:3
#修改副本数为2
ceph osd pool get mypool size 2

#为2就是允许挂一个OSD
ceph osd pool mypool min_size
min_size:2


#pg_num:查看当前PG的数量
$ ceph osd pool get mypool pg_num
pg num: 32

#crush_rule: 设置crush算法规则
$ ceph osd pool get mypool crush_rule
crush_ rule: replicated_rule #默认为副本池

#nodelete:控制是否可删除，默认可以
$ ceph osd pool get mypool nodelete
nodelete: false

#nopgchange:控制是否可更改存储池的pg num和pgp num
S cenh osd pool get mypool nopgchange

#修改指定pool的pg数量
$ ceph osd pool set mypool pg_num 64 
set pool1 pg_num to 64

##修改指定pool的pgp数量
$ ceph osd pool set mypool pgp_num 64 
#nosizechange:控制是否可以更改存储池的大小

$ ceph osd pool get mypool nosizechange
nosizechange: false #默认允许修改存储池大小

$ ceph osd pool get-quota mypool
quotas for pool 'mypool':
max objects: 1 k objects
max bytes : 10 GiB

#限制存储池最大写入大小
ceph osd pool set-quota mypool max bytes 21474836480


#noscrub和nodeep-scrub:控制是否不进行轻量扫描或是否深层扫描存储池，可临时解决高l/0问题
#查看 当前是否关闭轻量扫描数据，默认为不关闭，即开启
$ ceph osd pool get mypool noscrub
noscrub: false 
#可以修改某个指定的pool的轻量级扫描测量为true,即不执行轻量级扫描
$ ceph osd pool set mypool noscrub true
set pool 1 noscrub to true 

#再次 查看就不进行轻量级扫描了
$ ceph osd pool get mypool noscrub
noscrub: true 

#查看当前是否关闭深度扫描数据，默认为不关闭，即开启
$ ceph osd pool get mypool nodeep-scrub
nodeep-scrub: false

#再次查看就不执行深度扫描了
$ ceph osd pool get mypool nodeep-scrub
nodeep-scrub: true 


#scrub_ min_ interval: 集群存储池的最小清理时间间隔，默认值没有设置，可以通过配置文件中的osd_scrub_min_interval 参数指定间隔时间.
$ ceph osd pool get mypool scrub min interval
Error ENOENT: option 'scrub_min_interval' is not set on pool 'mypool'

#scrub_max_interval: 整理存储池的最大清理时间间隔，默认值没有设置，可以通过配置文件中的osd_scrub_max_interval 参数指定。

$ ceph osd pool get mypool scrub max interval
Error ENOENT: option 'scrub_max_interval' is not set on pool 'mypool'

#deep_scrub_interval: 深层整理存储池的时间间隔，默认值没有设置，可以通过配置文件中的osd_deep_scrub_interval 参数指定。

$ ceph osd pool get mypool deep_scrub_interval
Error ENOENT: option 'deep_scrub_interval' is not set on pool 'mypool'

#查看ceph node的默认配置:
[root@ceph-node1 ~]# ll /var/run/ceph/
total 0
Srxr-Xr-x 1 ceph ceph 0 Nov 3 12:22 ceph-osd.3.asok
SrwXr-Xr-x 1 ceph ceph 0 Nov 3 12:22 ceph-osd.6.asok
SrWXr-Xr-x 1 ceph ceph 0 Nov 3 12:23 ceph-osd.9.asok

[root@ceph-node1 ~]# ceph daemon osd.3 config show | grep scrub
    "mds_max_scrub_ops_in_progress": "5",
    "mon_scrub_inject_crc_mismatch": "0.000000",
    "mon_scrub_inject_missing_keys": "0.000000",
    "mon_scrub_jinterval": "86400"，
    "mon_scrub_max_keys": "100"，
    "mon_scrub_timeout": "300",，
    "mon_warn_not_deep_scrubbed": "0",
    "mon_warn_not_scrubbed": "0",
    "osd_debug_deep_scrub_sleep": "0.000000",
    "osd_deep_scrub_jinterval":_"604800.00000"，#定义深度清洗间隔，604800秒=7天
    "osd_deep_scrub_keys": "1024"，
    "osd_deep_scrub_Jarge_omap_object_key_threshold": "200000",
    "osd_deep_scrub_large_omap_object_value_sum_threshold": "1073741824",
    "osd_deep_scrub_randomize.ratio": "0.150000",
    "osd_deep_scrub.stride": "524288",
    "osd.deep_scrub.update_digest_min_age": "7200"，
    "osd.max_scrubs": "1"， #定义一个ceph OSD daemon内能够同时进行scrubbing的操作数 （启用几个线程扫描 默认是一个）
    "osd_op_queue_mclock_scrub_lim": "0.001000",
    "osd_op_queue_mclock_scrub_res": "0.000000",
    "osd_op_queue_mclock_scrub_wgt": "1.000000,
    "osd_requested_scrub_priority": "120"，
    "osd_scrub_auto_repair": "false",
    "osd_scrub_auto_repair_num_errors": "5"，
    "osd_scrub_backoff_ratio": "0.660000",
    "osd_scrub_begin_hour": "0"，
    "osd_scrub_begin_week_day": "0",
    "osd_scrub_chunk_max": "25",
    "osd_scrub_chunk_min": "5",
    "osd_scrub_cost": "52428800",
    "osd_scrub_during_recovery": "false",
    "osd_scrub_end_hour": "24",
    "osd_scrub_end_week_day": "7",
    "osd_scrub_interval_randomize_ratio": "0.500000",
    "osd_scrub_invalid_stats": "true", #定义scrub是否有效
    "osd_scrub_load_threshold": "0.500000",
    "osd_scrub_max_interval": "60480000000"，#定义最大执行scrub间隔，604800秒=7天
    "osd_scrub_max_preemptions": "5"，
    "osd_scrub_min_interval": 8640000000" #定义最小执行普通scrub间隔，86400秒=1天
    "osd_scrub_priority": "5",
    "osd_scrub_sleep": "0.000000",
```


## 4.10 存储池快照
快照用于读存储池中的数据进行备份与还原，创建快照需要占用的磁盘空间会比较大,取决于存储池中的数据大小，使用以下命令创建快照:

### 4.10.1 创建快照 
```bash
$ ceph osd pool ls

#命令1: ceph osd pool mksnap {pool-name} {snap-name}
$ ceph osd pool mksnap mypool mypool-snap
created pool mypool snap mypool-snap

#命令2: rados -P {pool-name} mksnap {snap-name}
$ rados -P mypool mksnap mypool-snap2
created pool mypool snap mypool-snap2

```

### 4.10.2 验证快照 
```bash
$ rados lssnap -p mypool
1  mypool-snap  2020.11.03 16:12:56
2  mypool-snap2 2020.11.03 16:13:40
2 snaps
```

### 4.10.3 回滚快照 
测试上传文件后创建快照，照后删除文件再还原文件,基于对象还原。`rados rollback <obj-name> <snap-name> roll back object to snap <snap-name>`
```bash
#上传文件
[ceph@ceph-deploy ceph-cluster]$ rados -P mypool put testile /etc/hosts

#验证文件
[ceph@ceph-deploy ceph-cluster]$ rados -P mypool ls 
msg1
testfile
my.conf


#创建快照
(ceph@ceph-deploy ceph-cluster]$ ceph pool mksnap mypool
mypool-snapshot001
created pool mypool snap mypool-snapshot001


#验证快照
[ceph@ceph-deploy ceph-cluster]$ rados lssnap -p mypool
3  mypool-snap   2020.11.04 14:11:41
4  mypool-snap2  2020.11.0414:1 1:49
5  mypool-conf-bak 2020.11.04 14:18:41
6  mypool-snapshot001 2020.11.0414:38:50
4 snaps



#删除文件
[ceph@ceph-deploy ceph-cluster]$ rados -P mypool rm testile
#删除文件后，无法再次删除文件，提升文件不存在
[ceph@ceph-deploy ceph-cluster$ rados -P mypool rm testfile
error removing mypool>testfile: (2) No such file or directory

#通过快照还原某个文件
[ceph@ceph-deploy ceph-cluster]$ rados rollback -P mypool testfile mypool-snapshot001
rolled back pool mypool to snapshot mypool-snapshot001

#再次执行删除就可以执行成功


```


### 4.10.4 删除快照 
`ceph osd pool rmsnap <poolname> <snap>`
```bash

[ceph@ceph-deploy ceph-cluster$ rados Issnap -P mypool
3 mypool-snap 2020.11.0414:11:41
4 mypool-snap2 2020.11.04 14:11:49
5 mypool-conf-bak 2020.11.04 14:18:41
6 mypool-snapshot001  2020.1 1.0414:38:50
4 snaps

[ceph@ceph-deploy ceph-cluster]$ ceph osd pool rmsnap mypool mypool-snap
removed pool mypool snap mypool-snap

[ceph@ceph-deploy ceph-cluster$ rados Issnap -P mypool
4 mypool-snap2 2020.11.04 14:11:49
5 mypool-conf-bak 2020.11.04 14:18:41
6 mvoool-snanshot001 2020.11.04 14:38:50

```


## 4.11 数据压缩
如果使用**bulestore**存储引擎，ceph 支持称为"实时数据压缩”即边压缩边保存数据的功能，该功能有助于节省磁盘空间，可以在BlueStore OSD 上创建的每个Ceph池上启用或禁用压缩，以节约磁盘空间，默认没有开启压缩，需要后期配置并开启。

### 4.11.1 启用压缩并指定压缩算法 
压缩会导致CPU利用率偏高
```bash
ceph-cluster]$ ceph osd pool set <pool name> compression_algorithm snappy #默认算
法为snappy
```

:::info
snappy:该配置为指定压缩使用的算法默认为**sanppy**,还有**none、zlib、 lz4、 zstd** 和**snappy**等算法，zstd压缩比好，但消耗CPU, lz4 和snappy对CPU占用较低，不建议使用zlib.
:::

### 4.11.2 指定压缩模式
```bash
ceph-cluster]$ ceph osd pool set <pool name> compression_mode aggressive
```

**aggressive**: 压缩的模式，有none、aggressive 、passive 和force 默认none **none**: 从不压缩数据.**passive**: 除非写操作具有可压缩的提示集，否则不要压缩数据.**aggressive**: 压缩数据，除非写操作具有不可压缩的提示集。**force**: 无论如何都尝试压缩数据，即使客户端暗示数据不可压缩也会压缩，也就是在所有情况下都使用压缩。

**存储池压缩设置参数:**`compression_algorithm`  压缩算法`compression_mode`  压缩模式

`compression_required_ratio` #压缩后与压缩前的压缩比，默认为.875`compression_max_blob_size`: #大于此的块在被压缩之前被分解成更小的blob(块)，此设置将覆盖bluestore压缩**max blob ***的全局设置。`compression_min_blob_size`: #小于此的块不压缩，此设置将覆盖bluestore压缩**min blob***的全局设置，


**全局压缩选项，这些可以配置到ceph.conf配置文件，作用于所有存储池**:
```bash
bluestore_compression_algorithm #压缩算法
bluestore_compression_mode #压缩模式
bluestore_compression_required_ratio #压缩后与压缩前的压缩比，默认为.875
bluestore_compression_min_blob_size #小于它的块不会被压缩,默认0
bluestore_compression_max_blob_size #大于它的块在压缩前会被拆成更小的块,默认0
bluestore_compression_min_blob_size_ssd #默认 8k
bluestore_compression_max_blob_size_ssd #默认 64k
bluestore_compression_min_blob_size_hdd #默认 128k
bluestore_compression_max_blob_size_hdd #默认 512k


到node 节点验证
[root@ceph-node3 ~]# ceph daemon osd.11 config show | grep compression



#修改压缩算法
[ceph@ceph-deploy ~]$ ceph osd pool set mypool compression algorithm snapy
set pool 2 compression algorithm to snappy

[ceph@ceph-deploy ~]$ ceph osd pool get mypool compression algorithm compression_algorithm:snappy

#修改压缩模式: 
[ceph@ceph-deploy ~]$ ceph osd pool set mypool compression mode passive
set pool 2 compression mode to passive

[ceph@ceph-deploy ~]$ ceph osd pool get mypool compression_mode
compression_mode: passive
```

